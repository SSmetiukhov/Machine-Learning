{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "35f163f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE on train data: [-8.88508501e-04 -8.88508503e-04 -8.88508477e-04 -8.87551426e-04\n",
      " -8.87544884e-04 -8.87614842e-04 -8.87614680e-04 -1.99899319e-05\n",
      " -8.87463774e-04 -8.87613352e-04]\n",
      "Mean RMSE on training data: -0.0008010918371154313\n",
      "RMSE on test data: [-142.01211892 -161.64767868 -177.15546764 -168.09992345 -153.54207085\n",
      " -228.14241647 -180.07364416 -206.93548977 -273.59258333 -290.70805692]\n",
      "Mean RMSE on test data: -198.19094501735123\n",
      "Best RMSE on test data: -142.0121189152066 , index:  0 \n",
      "\n",
      "R2 on train data: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "Mean R2 on training data: 0.9999999999136001\n",
      "R2 on test data: [-3.80953014 -4.52133493 -3.61538431 -3.66718436 -3.68559225 -5.692211\n",
      " -6.7866641  -6.13710489 -5.60073338 -9.0009391 ]\n",
      "Mean R2 on test data: -5.251667846534912\n",
      "Best R2 on test data: -3.615384314800444 , index:  2\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.gaussian_process.kernels import RBF, RationalQuadratic as RQ, ConstantKernel as C, WhiteKernel as Wh\n",
    "from sklearn.gaussian_process.kernels import Matern as M, DotProduct as Dt\n",
    "from sklearn.model_selection import cross_validate\n",
    "from statistics import mean\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn import preprocessing\n",
    "\n",
    "#setting up matrices \n",
    "steel_data = pd.read_csv('steel.csv')\n",
    "\n",
    "\n",
    "\n",
    "X = steel_data.iloc[:,:-1]\n",
    "y = steel_data.iloc[:,-1]\n",
    "\n",
    "\n",
    "model = GaussianProcessRegressor()\n",
    "\n",
    "#domain independent and domain specific measure of error\n",
    "scoring = ['neg_root_mean_squared_error', 'r2']\n",
    "#10-fold cross validation \n",
    "scores = cross_validate(model, X, y, scoring=scoring, cv=10, return_train_score=True, return_estimator=True)\n",
    "\n",
    "\n",
    "absolute_difference_function = lambda list_value : abs(list_value - target_value)\n",
    "\n",
    "target_value = 0\n",
    "print (\"RMSE on train data:\", scores['train_neg_root_mean_squared_error'])\n",
    "print (\"Mean RMSE on training data:\", mean(scores['train_neg_root_mean_squared_error']))\n",
    "print (\"RMSE on test data:\", scores['test_neg_root_mean_squared_error'])\n",
    "print(\"Mean RMSE on test data:\", mean(scores['test_neg_root_mean_squared_error']))\n",
    "best_rmse_score = min(scores['test_neg_root_mean_squared_error'], key=absolute_difference_function)\n",
    "best_rmse_index = np.where(scores['test_neg_root_mean_squared_error']==best_rmse_score)[0][0]\n",
    "print(\"Best RMSE on test data:\", best_rmse_score, ', index: ', best_rmse_index, '\\n')\n",
    "\n",
    "target_value = 1\n",
    "print (\"R2 on train data:\", scores['train_r2'])\n",
    "print(\"Mean R2 on training data:\", mean(scores['train_r2']))\n",
    "print (\"R2 on test data:\", scores['test_r2'])\n",
    "print(\"Mean R2 on test data:\", mean(scores['test_r2']))\n",
    "best_r2_score = min(scores['test_r2'], key=absolute_difference_function)\n",
    "best_r2_index = np.where(scores['test_r2']==best_r2_score)[0][0]\n",
    "print(\"Best R2 on test data:\", best_r2_score, ', index: ',  best_r2_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "0a34b2d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 3, 5, 7, 10, 15, 20, 30, 50, 100]\n",
      "RMSE on train data:\n",
      "    [-8.88508501e-04 -8.88508503e-04 -8.88508477e-04 -8.87551426e-04\n",
      " -8.87544884e-04 -8.87614842e-04 -8.87614680e-04 -1.99899319e-05\n",
      " -8.87463774e-04 -8.87613352e-04]\n",
      "    [-8.88508501e-04 -8.88508503e-04 -8.88508477e-04 -8.87551426e-04\n",
      " -8.87544884e-04 -8.87614842e-04 -8.87614680e-04 -1.99899319e-05\n",
      " -8.87463774e-04 -8.87613352e-04]\n",
      "    [-8.88508501e-04 -8.88508503e-04 -8.88508477e-04 -8.87551426e-04\n",
      " -8.87544884e-04 -8.87614842e-04 -8.87614680e-04 -1.99899319e-05\n",
      " -8.87463774e-04 -8.87613352e-04]\n",
      "    [-8.88508501e-04 -8.88508503e-04 -8.88508477e-04 -8.87551426e-04\n",
      " -8.87544884e-04 -8.87614842e-04 -8.87614680e-04 -1.99899319e-05\n",
      " -8.87463774e-04 -8.87613352e-04]\n",
      "    [-8.88508501e-04 -8.88508503e-04 -8.88508477e-04 -8.87551426e-04\n",
      " -8.87544884e-04 -8.87614842e-04 -8.87614680e-04 -1.99899319e-05\n",
      " -8.87463774e-04 -8.87613352e-04]\n",
      "    [-8.88508501e-04 -8.88508503e-04 -8.88508477e-04 -8.87551426e-04\n",
      " -8.87544884e-04 -8.87614842e-04 -8.87614680e-04 -1.99899319e-05\n",
      " -8.87463774e-04 -8.87613352e-04]\n",
      "    [-8.88508501e-04 -8.88508503e-04 -8.88508477e-04 -8.87551426e-04\n",
      " -8.87544884e-04 -8.87614842e-04 -8.87614680e-04 -1.99899319e-05\n",
      " -8.87463774e-04 -8.87613352e-04]\n",
      "    [-8.88508501e-04 -8.88508503e-04 -8.88508477e-04 -8.87551426e-04\n",
      " -8.87544884e-04 -8.87614842e-04 -8.87614680e-04 -1.99899319e-05\n",
      " -8.87463774e-04 -8.87613352e-04]\n",
      "    [-8.88508501e-04 -8.88508503e-04 -8.88508477e-04 -8.87551426e-04\n",
      " -8.87544884e-04 -8.87614842e-04 -8.87614680e-04 -1.99899319e-05\n",
      " -8.87463774e-04 -8.87613352e-04]\n",
      "    [-8.88508501e-04 -8.88508503e-04 -8.88508477e-04 -8.87551426e-04\n",
      " -8.87544884e-04 -8.87614842e-04 -8.87614680e-04 -1.99899319e-05\n",
      " -8.87463774e-04 -8.87613352e-04]\n",
      "    [-8.88508501e-04 -8.88508503e-04 -8.88508477e-04 -8.87551426e-04\n",
      " -8.87544884e-04 -8.87614842e-04 -8.87614680e-04 -1.99899319e-05\n",
      " -8.87463774e-04 -8.87613352e-04]\n",
      "Mean RMSE on training data:\n",
      "    -0.0008010918371154313\n",
      "    -0.0008010918371154313\n",
      "    -0.0008010918371154313\n",
      "    -0.0008010918371154313\n",
      "    -0.0008010918371154313\n",
      "    -0.0008010918371154313\n",
      "    -0.0008010918371154313\n",
      "    -0.0008010918371154313\n",
      "    -0.0008010918371154313\n",
      "    -0.0008010918371154313\n",
      "    -0.0008010918371154313\n",
      "RMSE on test data:\n",
      "    [-142.01211892 -161.64767868 -177.15546764 -168.09992345 -153.54207085\n",
      " -228.14241647 -180.07364416 -206.93548977 -273.59258333 -290.70805692]\n",
      "    [-142.01211892 -161.64767868 -177.15546764 -168.09992345 -153.54207085\n",
      " -228.14241647 -180.07364416 -206.93548977 -273.59258333 -290.70805692]\n",
      "    [-142.01211892 -161.64767868 -177.15546764 -168.09992345 -153.54207085\n",
      " -228.14241647 -180.07364416 -206.93548977 -273.59258333 -290.70805692]\n",
      "    [-142.01211892 -161.64767868 -177.15546764 -168.09992345 -153.54207085\n",
      " -228.14241647 -180.07364416 -206.93548977 -273.59258333 -290.70805692]\n",
      "    [-142.01211892 -161.64767868 -177.15546764 -168.09992345 -153.54207085\n",
      " -228.14241647 -180.07364416 -206.93548977 -273.59258333 -290.70805692]\n",
      "    [-142.01211892 -161.64767868 -177.15546764 -168.09992345 -153.54207085\n",
      " -228.14241647 -180.07364416 -206.93548977 -273.59258333 -290.70805692]\n",
      "    [-142.01211892 -161.64767868 -177.15546764 -168.09992345 -153.54207085\n",
      " -228.14241647 -180.07364416 -206.93548977 -273.59258333 -290.70805692]\n",
      "    [-142.01211892 -161.64767868 -177.15546764 -168.09992345 -153.54207085\n",
      " -228.14241647 -180.07364416 -206.93548977 -273.59258333 -290.70805692]\n",
      "    [-142.01211892 -161.64767868 -177.15546764 -168.09992345 -153.54207085\n",
      " -228.14241647 -180.07364416 -206.93548977 -273.59258333 -290.70805692]\n",
      "    [-142.01211892 -161.64767868 -177.15546764 -168.09992345 -153.54207085\n",
      " -228.14241647 -180.07364416 -206.93548977 -273.59258333 -290.70805692]\n",
      "    [-142.01211892 -161.64767868 -177.15546764 -168.09992345 -153.54207085\n",
      " -228.14241647 -180.07364416 -206.93548977 -273.59258333 -290.70805692]\n",
      "Mean RMSE on test data:\n",
      "    -198.19094501735123\n",
      "    -198.19094501735123\n",
      "    -198.19094501735123\n",
      "    -198.19094501735123\n",
      "    -198.19094501735123\n",
      "    -198.19094501735123\n",
      "    -198.19094501735123\n",
      "    -198.19094501735123\n",
      "    -198.19094501735123\n",
      "    -198.19094501735123\n",
      "    -198.19094501735123\n",
      "=================================================================\n",
      "R2 on train data:\n",
      "    [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "    [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "    [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "    [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "    [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "    [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "    [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "    [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "    [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "    [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "    [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "Mean R2 on training data:\n",
      "    0.9999999999136001\n",
      "    0.9999999999136001\n",
      "    0.9999999999136001\n",
      "    0.9999999999136001\n",
      "    0.9999999999136001\n",
      "    0.9999999999136001\n",
      "    0.9999999999136001\n",
      "    0.9999999999136001\n",
      "    0.9999999999136001\n",
      "    0.9999999999136001\n",
      "    0.9999999999136001\n",
      "R2 on test data:\n",
      "    [-3.80953014 -4.52133493 -3.61538431 -3.66718436 -3.68559225 -5.692211\n",
      " -6.7866641  -6.13710489 -5.60073338 -9.0009391 ]\n",
      "    [-3.80953014 -4.52133493 -3.61538431 -3.66718436 -3.68559225 -5.692211\n",
      " -6.7866641  -6.13710489 -5.60073338 -9.0009391 ]\n",
      "    [-3.80953014 -4.52133493 -3.61538431 -3.66718436 -3.68559225 -5.692211\n",
      " -6.7866641  -6.13710489 -5.60073338 -9.0009391 ]\n",
      "    [-3.80953014 -4.52133493 -3.61538431 -3.66718436 -3.68559225 -5.692211\n",
      " -6.7866641  -6.13710489 -5.60073338 -9.0009391 ]\n",
      "    [-3.80953014 -4.52133493 -3.61538431 -3.66718436 -3.68559225 -5.692211\n",
      " -6.7866641  -6.13710489 -5.60073338 -9.0009391 ]\n",
      "    [-3.80953014 -4.52133493 -3.61538431 -3.66718436 -3.68559225 -5.692211\n",
      " -6.7866641  -6.13710489 -5.60073338 -9.0009391 ]\n",
      "    [-3.80953014 -4.52133493 -3.61538431 -3.66718436 -3.68559225 -5.692211\n",
      " -6.7866641  -6.13710489 -5.60073338 -9.0009391 ]\n",
      "    [-3.80953014 -4.52133493 -3.61538431 -3.66718436 -3.68559225 -5.692211\n",
      " -6.7866641  -6.13710489 -5.60073338 -9.0009391 ]\n",
      "    [-3.80953014 -4.52133493 -3.61538431 -3.66718436 -3.68559225 -5.692211\n",
      " -6.7866641  -6.13710489 -5.60073338 -9.0009391 ]\n",
      "    [-3.80953014 -4.52133493 -3.61538431 -3.66718436 -3.68559225 -5.692211\n",
      " -6.7866641  -6.13710489 -5.60073338 -9.0009391 ]\n",
      "    [-3.80953014 -4.52133493 -3.61538431 -3.66718436 -3.68559225 -5.692211\n",
      " -6.7866641  -6.13710489 -5.60073338 -9.0009391 ]\n",
      "Mean R2 on test data:\n",
      "    -5.251667846534912\n",
      "    -5.251667846534912\n",
      "    -5.251667846534912\n",
      "    -5.251667846534912\n",
      "    -5.251667846534912\n",
      "    -5.251667846534912\n",
      "    -5.251667846534912\n",
      "    -5.251667846534912\n",
      "    -5.251667846534912\n",
      "    -5.251667846534912\n",
      "    -5.251667846534912\n"
     ]
    }
   ],
   "source": [
    "n_restarts_optimizers = [0, 1, 3, 5, 7, 10, 15, 20, 30 , 50, 100]\n",
    "n_restarts_optimizers_s = ['0', '1', '3', '5', '7', '10', '15', '20', '30' , '50', '100']\n",
    "print(n_restarts_optimizers)\n",
    "\n",
    "r2_training_i = []\n",
    "r2_training_mean_i = []\n",
    "r2_test_i = []\n",
    "r2_test_mean_i = []\n",
    "\n",
    "rmse_training_i = []\n",
    "rmse_training_mean_i = []\n",
    "rmse_test_i = []\n",
    "rmse_test_mean_i = []\n",
    "for restarn_optimizer in n_restarts_optimizers:\n",
    "    \n",
    "    model_i = GaussianProcessRegressor(n_restarts_optimizer = restarn_optimizer)\n",
    "\n",
    "    \n",
    "    #10-fold cross validation \n",
    "    scores = cross_validate(model_i, X, y, scoring=scoring, cv=10, return_train_score=True, return_estimator=True)\n",
    "    \n",
    "    \n",
    "    \n",
    "    # compute rmse on the training and test set predictions\n",
    "    rmse_training_i.append(scores['train_neg_root_mean_squared_error'])\n",
    "    rmse_training_mean_i.append(mean(scores['train_neg_root_mean_squared_error']))\n",
    "    rmse_test_i.append(scores['test_neg_root_mean_squared_error'])\n",
    "    rmse_test_mean_i.append(mean(scores['test_neg_root_mean_squared_error']))\n",
    "    \n",
    "    # compute r2 on the training and test set predictions\n",
    "    r2_training_i.append(scores['train_r2'])\n",
    "    r2_training_mean_i.append(mean(scores['train_r2']))\n",
    "    r2_test_i.append(scores['test_r2'])\n",
    "    r2_test_mean_i.append(mean(scores['test_r2']))\n",
    "\n",
    "\n",
    "\n",
    "print (\"RMSE on train data:\", *rmse_training_i, sep='\\n    ') \n",
    "print (\"Mean RMSE on training data:\", *rmse_training_mean_i, sep='\\n    ')\n",
    "print (\"RMSE on test data:\", *rmse_test_i, sep='\\n    ') \n",
    "print (\"Mean RMSE on test data:\", *rmse_test_mean_i, sep='\\n    ')\n",
    "\n",
    "print('=================================================================')\n",
    "\n",
    "print (\"R2 on train data:\", *r2_training_i, sep='\\n    ') \n",
    "print (\"Mean R2 on training data:\", *r2_training_mean_i, sep='\\n    ')\n",
    "print (\"R2 on test data:\", *r2_test_i, sep='\\n    ') \n",
    "print (\"Mean R2 on test data:\", *r2_test_mean_i, sep='\\n    ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4df49a34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.scatter(n_restarts_optimizers_s, r2_training_mean_i,marker=\"+\")\n",
    "plt.scatter(n_restarts_optimizers_s, r2_test_mean_i,marker=\"x\")\n",
    "\n",
    "\n",
    "plt.xlim([-0.1, 11])\n",
    "plt.ylim([-6, 1.1])\n",
    "plt.xlabel(\"Restarts optimizers_s\")\n",
    "plt.ylabel(\"R2\")\n",
    "legend_labels = [\"Train\", \"Test\"]\n",
    "plt.legend(frameon=False, loc=4,labels=legend_labels,  borderpad=1)\n",
    "plt.title(\"Effect of restarts optimizers_s on training and test set r2\", fontsize=10)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af27f243",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "74d10f11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Tuning hyper-parameters for [{'alpha': [0.01, 0.001], 'kernel': [RBF(length_scale=0.1), RBF(length_scale=10)]}]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sergey\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:420: ConvergenceWarning: The optimal value found for dimension 0 of parameter length_scale is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Sergey\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:420: ConvergenceWarning: The optimal value found for dimension 0 of parameter length_scale is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Sergey\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:420: ConvergenceWarning: The optimal value found for dimension 0 of parameter length_scale is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Sergey\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:420: ConvergenceWarning: The optimal value found for dimension 0 of parameter length_scale is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Sergey\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:420: ConvergenceWarning: The optimal value found for dimension 0 of parameter length_scale is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Sergey\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:420: ConvergenceWarning: The optimal value found for dimension 0 of parameter length_scale is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Sergey\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:420: ConvergenceWarning: The optimal value found for dimension 0 of parameter length_scale is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Sergey\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:420: ConvergenceWarning: The optimal value found for dimension 0 of parameter length_scale is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'alpha': 0.01, 'kernel': RBF(length_scale=0.1)}\n",
      "# Tuning hyper-parameters for [{'alpha': [0.01, 0.001], 'kernel': [DotProduct(sigma_0=0.1), DotProduct(sigma_0=10)]}]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sergey\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\gaussian_process\\_gpr.py:596: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  _check_optimize_result(\"lbfgs\", opt_res)\n",
      "C:\\Users\\Sergey\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:430: ConvergenceWarning: The optimal value found for dimension 0 of parameter sigma_0 is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Sergey\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\gaussian_process\\_gpr.py:596: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  _check_optimize_result(\"lbfgs\", opt_res)\n",
      "C:\\Users\\Sergey\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:430: ConvergenceWarning: The optimal value found for dimension 0 of parameter sigma_0 is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Sergey\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\gaussian_process\\_gpr.py:596: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  _check_optimize_result(\"lbfgs\", opt_res)\n",
      "C:\\Users\\Sergey\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\gaussian_process\\_gpr.py:596: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  _check_optimize_result(\"lbfgs\", opt_res)\n",
      "C:\\Users\\Sergey\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:430: ConvergenceWarning: The optimal value found for dimension 0 of parameter sigma_0 is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Sergey\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:430: ConvergenceWarning: The optimal value found for dimension 0 of parameter sigma_0 is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Sergey\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:430: ConvergenceWarning: The optimal value found for dimension 0 of parameter sigma_0 is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Sergey\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\gaussian_process\\_gpr.py:596: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  _check_optimize_result(\"lbfgs\", opt_res)\n",
      "C:\\Users\\Sergey\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\gaussian_process\\_gpr.py:596: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  _check_optimize_result(\"lbfgs\", opt_res)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'alpha': 0.01, 'kernel': DotProduct(sigma_0=10)}\n",
      "# Tuning hyper-parameters for [{'alpha': [0.01, 0.001], 'kernel': [RationalQuadratic(alpha=1, length_scale=0.1), RationalQuadratic(alpha=1, length_scale=10)]}]\n",
      "\n",
      "{'alpha': 0.001, 'kernel': RationalQuadratic(alpha=1, length_scale=10)}\n",
      "# Tuning hyper-parameters for [{'alpha': [0.01, 0.001], 'kernel': [Matern(length_scale=0.1, nu=1.5), Matern(length_scale=10, nu=1.5)]}]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sergey\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:420: ConvergenceWarning: The optimal value found for dimension 0 of parameter length_scale is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Sergey\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:420: ConvergenceWarning: The optimal value found for dimension 0 of parameter length_scale is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Sergey\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:420: ConvergenceWarning: The optimal value found for dimension 0 of parameter length_scale is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Sergey\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:420: ConvergenceWarning: The optimal value found for dimension 0 of parameter length_scale is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Sergey\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:420: ConvergenceWarning: The optimal value found for dimension 0 of parameter length_scale is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Sergey\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:420: ConvergenceWarning: The optimal value found for dimension 0 of parameter length_scale is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Sergey\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:420: ConvergenceWarning: The optimal value found for dimension 0 of parameter length_scale is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Sergey\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sklearn\\gaussian_process\\kernels.py:420: ConvergenceWarning: The optimal value found for dimension 0 of parameter length_scale is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'alpha': 0.01, 'kernel': Matern(length_scale=0.1, nu=1.5)}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "param_grids = [[{\n",
    "    \"alpha\":  [1e-2, 1e-3],\n",
    "    \"kernel\": [RBF(L) for L in np.logspace(-1, 1, 2)]\n",
    "}], [{\n",
    "    \"alpha\":  [1e-2, 1e-3],\n",
    "    \"kernel\": [Dt(sigma_0) for sigma_0 in np.logspace(-1, 1, 2)]\n",
    "}], [{\n",
    "    \"alpha\":  [1e-2, 1e-3],\n",
    "    \"kernel\": [RQ(L) for L in np.logspace(-1, 1, 2)]\n",
    "}], [{\n",
    "    \"alpha\":  [1e-2, 1e-3],\n",
    "    \"kernel\": [M(L) for L in np.logspace(-1, 1, 2)]\n",
    "}]]\n",
    "kernels = [RBF(), Dt(), RQ(), M()]\n",
    "kernels = ['RBF', 'Dt', 'Rat Quad', 'Mattern']\n",
    "\n",
    "gp = GaussianProcessRegressor()\n",
    "for j in range (len(param_grids)):\n",
    "    print(\"# Tuning hyper-parameters for %s\" % param_grids[j])\n",
    "    print()\n",
    "\n",
    "    clf = GridSearchCV(estimator=gp, param_grid=param_grids[j], cv=4, scoring='r2')\n",
    "    clf.fit(X, y)\n",
    "    kernels[j] = clf.best_params_\n",
    "    print(clf.best_params_)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7a982654",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE on train data kernel = \n",
      "    {'alpha': 0.01, 'kernel': RBF(length_scale=0.1)}\n",
      "    [-8.88508501e-04 -8.88508503e-04 -8.88508477e-04 -8.87551426e-04\n",
      " -8.87544884e-04 -8.87614842e-04 -8.87614680e-04 -1.99899319e-05\n",
      " -8.87463774e-04 -8.87613352e-04]\n",
      "    [-8.88508501e-04 -8.88508503e-04 -8.88508477e-04 -8.87551426e-04\n",
      " -8.87544884e-04 -8.87614842e-04 -8.87614680e-04 -1.99899319e-05\n",
      " -8.87463774e-04 -8.87613352e-04]\n",
      "    [-8.88508501e-04 -8.88508503e-04 -8.88508477e-04 -8.87551426e-04\n",
      " -8.87544884e-04 -8.87614842e-04 -8.87614680e-04 -1.99899319e-05\n",
      " -8.87463774e-04 -8.87613352e-04]\n",
      "    [-8.88508501e-04 -8.88508503e-04 -8.88508477e-04 -8.87551426e-04\n",
      " -8.87544884e-04 -8.87614842e-04 -8.87614680e-04 -1.99899319e-05\n",
      " -8.87463774e-04 -8.87613352e-04]\n",
      "    [-8.88508501e-04 -8.88508503e-04 -8.88508477e-04 -8.87551426e-04\n",
      " -8.87544884e-04 -8.87614842e-04 -8.87614680e-04 -1.99899319e-05\n",
      " -8.87463774e-04 -8.87613352e-04]\n",
      "    [-8.88508501e-04 -8.88508503e-04 -8.88508477e-04 -8.87551426e-04\n",
      " -8.87544884e-04 -8.87614842e-04 -8.87614680e-04 -1.99899319e-05\n",
      " -8.87463774e-04 -8.87613352e-04]\n",
      "    [-8.88508501e-04 -8.88508503e-04 -8.88508477e-04 -8.87551426e-04\n",
      " -8.87544884e-04 -8.87614842e-04 -8.87614680e-04 -1.99899319e-05\n",
      " -8.87463774e-04 -8.87613352e-04]\n",
      "    [-8.88508501e-04 -8.88508503e-04 -8.88508477e-04 -8.87551426e-04\n",
      " -8.87544884e-04 -8.87614842e-04 -8.87614680e-04 -1.99899319e-05\n",
      " -8.87463774e-04 -8.87613352e-04]\n",
      "    [-8.88508501e-04 -8.88508503e-04 -8.88508477e-04 -8.87551426e-04\n",
      " -8.87544884e-04 -8.87614842e-04 -8.87614680e-04 -1.99899319e-05\n",
      " -8.87463774e-04 -8.87613352e-04]\n",
      "    [-8.88508501e-04 -8.88508503e-04 -8.88508477e-04 -8.87551426e-04\n",
      " -8.87544884e-04 -8.87614842e-04 -8.87614680e-04 -1.99899319e-05\n",
      " -8.87463774e-04 -8.87613352e-04]\n",
      "Mean RMSE on training data kernel = \n",
      "    {'alpha': 0.01, 'kernel': RBF(length_scale=0.1)}\n",
      "    -0.0008010918371154313\n",
      "    -0.0008010918371154313\n",
      "    -0.0008010918371154313\n",
      "    -0.0008010918371154313\n",
      "    -0.0008010918371154313\n",
      "    -0.0008010918371154313\n",
      "    -0.0008010918371154313\n",
      "    -0.0008010918371154313\n",
      "    -0.0008010918371154313\n",
      "    -0.0008010918371154313\n",
      "RMSE on test data kernel = \n",
      "    {'alpha': 0.01, 'kernel': RBF(length_scale=0.1)}\n",
      "    [-142.01211892 -161.64767868 -177.15546764 -168.09992345 -153.54207085\n",
      " -228.14241647 -180.07364416 -206.93548977 -273.59258333 -290.70805692]\n",
      "    [-142.01211892 -161.64767868 -177.15546764 -168.09992345 -153.54207085\n",
      " -228.14241647 -180.07364416 -206.93548977 -273.59258333 -290.70805692]\n",
      "    [-142.01211892 -161.64767868 -177.15546764 -168.09992345 -153.54207085\n",
      " -228.14241647 -180.07364416 -206.93548977 -273.59258333 -290.70805692]\n",
      "    [-142.01211892 -161.64767868 -177.15546764 -168.09992345 -153.54207085\n",
      " -228.14241647 -180.07364416 -206.93548977 -273.59258333 -290.70805692]\n",
      "    [-142.01211892 -161.64767868 -177.15546764 -168.09992345 -153.54207085\n",
      " -228.14241647 -180.07364416 -206.93548977 -273.59258333 -290.70805692]\n",
      "    [-142.01211892 -161.64767868 -177.15546764 -168.09992345 -153.54207085\n",
      " -228.14241647 -180.07364416 -206.93548977 -273.59258333 -290.70805692]\n",
      "    [-142.01211892 -161.64767868 -177.15546764 -168.09992345 -153.54207085\n",
      " -228.14241647 -180.07364416 -206.93548977 -273.59258333 -290.70805692]\n",
      "    [-142.01211892 -161.64767868 -177.15546764 -168.09992345 -153.54207085\n",
      " -228.14241647 -180.07364416 -206.93548977 -273.59258333 -290.70805692]\n",
      "    [-142.01211892 -161.64767868 -177.15546764 -168.09992345 -153.54207085\n",
      " -228.14241647 -180.07364416 -206.93548977 -273.59258333 -290.70805692]\n",
      "    [-142.01211892 -161.64767868 -177.15546764 -168.09992345 -153.54207085\n",
      " -228.14241647 -180.07364416 -206.93548977 -273.59258333 -290.70805692]\n",
      "Mean RMSE on test data kernel = \n",
      "    {'alpha': 0.01, 'kernel': RBF(length_scale=0.1)}\n",
      "    -198.19094501735123\n",
      "    -198.19094501735123\n",
      "    -198.19094501735123\n",
      "    -198.19094501735123\n",
      "    -198.19094501735123\n",
      "    -198.19094501735123\n",
      "    -198.19094501735123\n",
      "    -198.19094501735123\n",
      "    -198.19094501735123\n",
      "    -198.19094501735123\n",
      "=================================================================\n",
      "R2 on train data kernel = \n",
      "    {'alpha': 0.01, 'kernel': RBF(length_scale=0.1)}\n",
      "    [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "    [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "    [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "    [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "    [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "    [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "    [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "    [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "    [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "    [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "Mean R2 on training data kernel = \n",
      "    {'alpha': 0.01, 'kernel': RBF(length_scale=0.1)}\n",
      "    0.9999999999136001\n",
      "    0.9999999999136001\n",
      "    0.9999999999136001\n",
      "    0.9999999999136001\n",
      "    0.9999999999136001\n",
      "    0.9999999999136001\n",
      "    0.9999999999136001\n",
      "    0.9999999999136001\n",
      "    0.9999999999136001\n",
      "    0.9999999999136001\n",
      "R2 on test data kernel = \n",
      "    {'alpha': 0.01, 'kernel': RBF(length_scale=0.1)}\n",
      "    [-3.80953014 -4.52133493 -3.61538431 -3.66718436 -3.68559225 -5.692211\n",
      " -6.7866641  -6.13710489 -5.60073338 -9.0009391 ]\n",
      "    [-3.80953014 -4.52133493 -3.61538431 -3.66718436 -3.68559225 -5.692211\n",
      " -6.7866641  -6.13710489 -5.60073338 -9.0009391 ]\n",
      "    [-3.80953014 -4.52133493 -3.61538431 -3.66718436 -3.68559225 -5.692211\n",
      " -6.7866641  -6.13710489 -5.60073338 -9.0009391 ]\n",
      "    [-3.80953014 -4.52133493 -3.61538431 -3.66718436 -3.68559225 -5.692211\n",
      " -6.7866641  -6.13710489 -5.60073338 -9.0009391 ]\n",
      "    [-3.80953014 -4.52133493 -3.61538431 -3.66718436 -3.68559225 -5.692211\n",
      " -6.7866641  -6.13710489 -5.60073338 -9.0009391 ]\n",
      "    [-3.80953014 -4.52133493 -3.61538431 -3.66718436 -3.68559225 -5.692211\n",
      " -6.7866641  -6.13710489 -5.60073338 -9.0009391 ]\n",
      "    [-3.80953014 -4.52133493 -3.61538431 -3.66718436 -3.68559225 -5.692211\n",
      " -6.7866641  -6.13710489 -5.60073338 -9.0009391 ]\n",
      "    [-3.80953014 -4.52133493 -3.61538431 -3.66718436 -3.68559225 -5.692211\n",
      " -6.7866641  -6.13710489 -5.60073338 -9.0009391 ]\n",
      "    [-3.80953014 -4.52133493 -3.61538431 -3.66718436 -3.68559225 -5.692211\n",
      " -6.7866641  -6.13710489 -5.60073338 -9.0009391 ]\n",
      "    [-3.80953014 -4.52133493 -3.61538431 -3.66718436 -3.68559225 -5.692211\n",
      " -6.7866641  -6.13710489 -5.60073338 -9.0009391 ]\n",
      "Mean R2 on test data kernel = \n",
      "    {'alpha': 0.01, 'kernel': RBF(length_scale=0.1)}\n",
      "    -5.251667846534912\n",
      "    -5.251667846534912\n",
      "    -5.251667846534912\n",
      "    -5.251667846534912\n",
      "    -5.251667846534912\n",
      "    -5.251667846534912\n",
      "    -5.251667846534912\n",
      "    -5.251667846534912\n",
      "    -5.251667846534912\n",
      "    -5.251667846534912\n",
      "=================================================================\n",
      "RMSE on train data kernel = \n",
      "    {'alpha': 0.01, 'kernel': DotProduct(sigma_0=10)}\n",
      "    [-8.88508501e-04 -8.88508503e-04 -8.88508477e-04 -8.87551426e-04\n",
      " -8.87544884e-04 -8.87614842e-04 -8.87614680e-04 -1.99899319e-05\n",
      " -8.87463774e-04 -8.87613352e-04]\n",
      "    [-8.88508501e-04 -8.88508503e-04 -8.88508477e-04 -8.87551426e-04\n",
      " -8.87544884e-04 -8.87614842e-04 -8.87614680e-04 -1.99899319e-05\n",
      " -8.87463774e-04 -8.87613352e-04]\n",
      "    [-8.88508501e-04 -8.88508503e-04 -8.88508477e-04 -8.87551426e-04\n",
      " -8.87544884e-04 -8.87614842e-04 -8.87614680e-04 -1.99899319e-05\n",
      " -8.87463774e-04 -8.87613352e-04]\n",
      "    [-8.88508501e-04 -8.88508503e-04 -8.88508477e-04 -8.87551426e-04\n",
      " -8.87544884e-04 -8.87614842e-04 -8.87614680e-04 -1.99899319e-05\n",
      " -8.87463774e-04 -8.87613352e-04]\n",
      "    [-8.88508501e-04 -8.88508503e-04 -8.88508477e-04 -8.87551426e-04\n",
      " -8.87544884e-04 -8.87614842e-04 -8.87614680e-04 -1.99899319e-05\n",
      " -8.87463774e-04 -8.87613352e-04]\n",
      "    [-8.88508501e-04 -8.88508503e-04 -8.88508477e-04 -8.87551426e-04\n",
      " -8.87544884e-04 -8.87614842e-04 -8.87614680e-04 -1.99899319e-05\n",
      " -8.87463774e-04 -8.87613352e-04]\n",
      "    [-8.88508501e-04 -8.88508503e-04 -8.88508477e-04 -8.87551426e-04\n",
      " -8.87544884e-04 -8.87614842e-04 -8.87614680e-04 -1.99899319e-05\n",
      " -8.87463774e-04 -8.87613352e-04]\n",
      "    [-8.88508501e-04 -8.88508503e-04 -8.88508477e-04 -8.87551426e-04\n",
      " -8.87544884e-04 -8.87614842e-04 -8.87614680e-04 -1.99899319e-05\n",
      " -8.87463774e-04 -8.87613352e-04]\n",
      "    [-8.88508501e-04 -8.88508503e-04 -8.88508477e-04 -8.87551426e-04\n",
      " -8.87544884e-04 -8.87614842e-04 -8.87614680e-04 -1.99899319e-05\n",
      " -8.87463774e-04 -8.87613352e-04]\n",
      "    [-8.88508501e-04 -8.88508503e-04 -8.88508477e-04 -8.87551426e-04\n",
      " -8.87544884e-04 -8.87614842e-04 -8.87614680e-04 -1.99899319e-05\n",
      " -8.87463774e-04 -8.87613352e-04]\n",
      "Mean RMSE on training data kernel = \n",
      "    {'alpha': 0.01, 'kernel': DotProduct(sigma_0=10)}\n",
      "    -0.0008010918371154313\n",
      "    -0.0008010918371154313\n",
      "    -0.0008010918371154313\n",
      "    -0.0008010918371154313\n",
      "    -0.0008010918371154313\n",
      "    -0.0008010918371154313\n",
      "    -0.0008010918371154313\n",
      "    -0.0008010918371154313\n",
      "    -0.0008010918371154313\n",
      "    -0.0008010918371154313\n",
      "RMSE on test data kernel = \n",
      "    {'alpha': 0.01, 'kernel': DotProduct(sigma_0=10)}\n",
      "    [-142.01211892 -161.64767868 -177.15546764 -168.09992345 -153.54207085\n",
      " -228.14241647 -180.07364416 -206.93548977 -273.59258333 -290.70805692]\n",
      "    [-142.01211892 -161.64767868 -177.15546764 -168.09992345 -153.54207085\n",
      " -228.14241647 -180.07364416 -206.93548977 -273.59258333 -290.70805692]\n",
      "    [-142.01211892 -161.64767868 -177.15546764 -168.09992345 -153.54207085\n",
      " -228.14241647 -180.07364416 -206.93548977 -273.59258333 -290.70805692]\n",
      "    [-142.01211892 -161.64767868 -177.15546764 -168.09992345 -153.54207085\n",
      " -228.14241647 -180.07364416 -206.93548977 -273.59258333 -290.70805692]\n",
      "    [-142.01211892 -161.64767868 -177.15546764 -168.09992345 -153.54207085\n",
      " -228.14241647 -180.07364416 -206.93548977 -273.59258333 -290.70805692]\n",
      "    [-142.01211892 -161.64767868 -177.15546764 -168.09992345 -153.54207085\n",
      " -228.14241647 -180.07364416 -206.93548977 -273.59258333 -290.70805692]\n",
      "    [-142.01211892 -161.64767868 -177.15546764 -168.09992345 -153.54207085\n",
      " -228.14241647 -180.07364416 -206.93548977 -273.59258333 -290.70805692]\n",
      "    [-142.01211892 -161.64767868 -177.15546764 -168.09992345 -153.54207085\n",
      " -228.14241647 -180.07364416 -206.93548977 -273.59258333 -290.70805692]\n",
      "    [-142.01211892 -161.64767868 -177.15546764 -168.09992345 -153.54207085\n",
      " -228.14241647 -180.07364416 -206.93548977 -273.59258333 -290.70805692]\n",
      "    [-142.01211892 -161.64767868 -177.15546764 -168.09992345 -153.54207085\n",
      " -228.14241647 -180.07364416 -206.93548977 -273.59258333 -290.70805692]\n",
      "Mean RMSE on test data kernel = \n",
      "    {'alpha': 0.01, 'kernel': DotProduct(sigma_0=10)}\n",
      "    -198.19094501735123\n",
      "    -198.19094501735123\n",
      "    -198.19094501735123\n",
      "    -198.19094501735123\n",
      "    -198.19094501735123\n",
      "    -198.19094501735123\n",
      "    -198.19094501735123\n",
      "    -198.19094501735123\n",
      "    -198.19094501735123\n",
      "    -198.19094501735123\n",
      "=================================================================\n",
      "R2 on train data kernel = \n",
      "    {'alpha': 0.01, 'kernel': DotProduct(sigma_0=10)}\n",
      "    [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "    [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "    [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "    [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "    [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "    [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "    [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "    [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "    [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "    [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "Mean R2 on training data kernel = \n",
      "    {'alpha': 0.01, 'kernel': DotProduct(sigma_0=10)}\n",
      "    0.9999999999136001\n",
      "    0.9999999999136001\n",
      "    0.9999999999136001\n",
      "    0.9999999999136001\n",
      "    0.9999999999136001\n",
      "    0.9999999999136001\n",
      "    0.9999999999136001\n",
      "    0.9999999999136001\n",
      "    0.9999999999136001\n",
      "    0.9999999999136001\n",
      "R2 on test data kernel = \n",
      "    {'alpha': 0.01, 'kernel': DotProduct(sigma_0=10)}\n",
      "    [-3.80953014 -4.52133493 -3.61538431 -3.66718436 -3.68559225 -5.692211\n",
      " -6.7866641  -6.13710489 -5.60073338 -9.0009391 ]\n",
      "    [-3.80953014 -4.52133493 -3.61538431 -3.66718436 -3.68559225 -5.692211\n",
      " -6.7866641  -6.13710489 -5.60073338 -9.0009391 ]\n",
      "    [-3.80953014 -4.52133493 -3.61538431 -3.66718436 -3.68559225 -5.692211\n",
      " -6.7866641  -6.13710489 -5.60073338 -9.0009391 ]\n",
      "    [-3.80953014 -4.52133493 -3.61538431 -3.66718436 -3.68559225 -5.692211\n",
      " -6.7866641  -6.13710489 -5.60073338 -9.0009391 ]\n",
      "    [-3.80953014 -4.52133493 -3.61538431 -3.66718436 -3.68559225 -5.692211\n",
      " -6.7866641  -6.13710489 -5.60073338 -9.0009391 ]\n",
      "    [-3.80953014 -4.52133493 -3.61538431 -3.66718436 -3.68559225 -5.692211\n",
      " -6.7866641  -6.13710489 -5.60073338 -9.0009391 ]\n",
      "    [-3.80953014 -4.52133493 -3.61538431 -3.66718436 -3.68559225 -5.692211\n",
      " -6.7866641  -6.13710489 -5.60073338 -9.0009391 ]\n",
      "    [-3.80953014 -4.52133493 -3.61538431 -3.66718436 -3.68559225 -5.692211\n",
      " -6.7866641  -6.13710489 -5.60073338 -9.0009391 ]\n",
      "    [-3.80953014 -4.52133493 -3.61538431 -3.66718436 -3.68559225 -5.692211\n",
      " -6.7866641  -6.13710489 -5.60073338 -9.0009391 ]\n",
      "    [-3.80953014 -4.52133493 -3.61538431 -3.66718436 -3.68559225 -5.692211\n",
      " -6.7866641  -6.13710489 -5.60073338 -9.0009391 ]\n",
      "Mean R2 on test data kernel = \n",
      "    {'alpha': 0.01, 'kernel': DotProduct(sigma_0=10)}\n",
      "    -5.251667846534912\n",
      "    -5.251667846534912\n",
      "    -5.251667846534912\n",
      "    -5.251667846534912\n",
      "    -5.251667846534912\n",
      "    -5.251667846534912\n",
      "    -5.251667846534912\n",
      "    -5.251667846534912\n",
      "    -5.251667846534912\n",
      "    -5.251667846534912\n",
      "=================================================================\n",
      "RMSE on train data kernel = \n",
      "    {'alpha': 0.001, 'kernel': RationalQuadratic(alpha=1, length_scale=10)}\n",
      "    [-8.88508501e-04 -8.88508503e-04 -8.88508477e-04 -8.87551426e-04\n",
      " -8.87544884e-04 -8.87614842e-04 -8.87614680e-04 -1.99899319e-05\n",
      " -8.87463774e-04 -8.87613352e-04]\n",
      "    [-8.88508501e-04 -8.88508503e-04 -8.88508477e-04 -8.87551426e-04\n",
      " -8.87544884e-04 -8.87614842e-04 -8.87614680e-04 -1.99899319e-05\n",
      " -8.87463774e-04 -8.87613352e-04]\n",
      "    [-8.88508501e-04 -8.88508503e-04 -8.88508477e-04 -8.87551426e-04\n",
      " -8.87544884e-04 -8.87614842e-04 -8.87614680e-04 -1.99899319e-05\n",
      " -8.87463774e-04 -8.87613352e-04]\n",
      "    [-8.88508501e-04 -8.88508503e-04 -8.88508477e-04 -8.87551426e-04\n",
      " -8.87544884e-04 -8.87614842e-04 -8.87614680e-04 -1.99899319e-05\n",
      " -8.87463774e-04 -8.87613352e-04]\n",
      "    [-8.88508501e-04 -8.88508503e-04 -8.88508477e-04 -8.87551426e-04\n",
      " -8.87544884e-04 -8.87614842e-04 -8.87614680e-04 -1.99899319e-05\n",
      " -8.87463774e-04 -8.87613352e-04]\n",
      "    [-8.88508501e-04 -8.88508503e-04 -8.88508477e-04 -8.87551426e-04\n",
      " -8.87544884e-04 -8.87614842e-04 -8.87614680e-04 -1.99899319e-05\n",
      " -8.87463774e-04 -8.87613352e-04]\n",
      "    [-8.88508501e-04 -8.88508503e-04 -8.88508477e-04 -8.87551426e-04\n",
      " -8.87544884e-04 -8.87614842e-04 -8.87614680e-04 -1.99899319e-05\n",
      " -8.87463774e-04 -8.87613352e-04]\n",
      "    [-8.88508501e-04 -8.88508503e-04 -8.88508477e-04 -8.87551426e-04\n",
      " -8.87544884e-04 -8.87614842e-04 -8.87614680e-04 -1.99899319e-05\n",
      " -8.87463774e-04 -8.87613352e-04]\n",
      "    [-8.88508501e-04 -8.88508503e-04 -8.88508477e-04 -8.87551426e-04\n",
      " -8.87544884e-04 -8.87614842e-04 -8.87614680e-04 -1.99899319e-05\n",
      " -8.87463774e-04 -8.87613352e-04]\n",
      "    [-8.88508501e-04 -8.88508503e-04 -8.88508477e-04 -8.87551426e-04\n",
      " -8.87544884e-04 -8.87614842e-04 -8.87614680e-04 -1.99899319e-05\n",
      " -8.87463774e-04 -8.87613352e-04]\n",
      "Mean RMSE on training data kernel = \n",
      "    {'alpha': 0.001, 'kernel': RationalQuadratic(alpha=1, length_scale=10)}\n",
      "    -0.0008010918371154313\n",
      "    -0.0008010918371154313\n",
      "    -0.0008010918371154313\n",
      "    -0.0008010918371154313\n",
      "    -0.0008010918371154313\n",
      "    -0.0008010918371154313\n",
      "    -0.0008010918371154313\n",
      "    -0.0008010918371154313\n",
      "    -0.0008010918371154313\n",
      "    -0.0008010918371154313\n",
      "RMSE on test data kernel = \n",
      "    {'alpha': 0.001, 'kernel': RationalQuadratic(alpha=1, length_scale=10)}\n",
      "    [-142.01211892 -161.64767868 -177.15546764 -168.09992345 -153.54207085\n",
      " -228.14241647 -180.07364416 -206.93548977 -273.59258333 -290.70805692]\n",
      "    [-142.01211892 -161.64767868 -177.15546764 -168.09992345 -153.54207085\n",
      " -228.14241647 -180.07364416 -206.93548977 -273.59258333 -290.70805692]\n",
      "    [-142.01211892 -161.64767868 -177.15546764 -168.09992345 -153.54207085\n",
      " -228.14241647 -180.07364416 -206.93548977 -273.59258333 -290.70805692]\n",
      "    [-142.01211892 -161.64767868 -177.15546764 -168.09992345 -153.54207085\n",
      " -228.14241647 -180.07364416 -206.93548977 -273.59258333 -290.70805692]\n",
      "    [-142.01211892 -161.64767868 -177.15546764 -168.09992345 -153.54207085\n",
      " -228.14241647 -180.07364416 -206.93548977 -273.59258333 -290.70805692]\n",
      "    [-142.01211892 -161.64767868 -177.15546764 -168.09992345 -153.54207085\n",
      " -228.14241647 -180.07364416 -206.93548977 -273.59258333 -290.70805692]\n",
      "    [-142.01211892 -161.64767868 -177.15546764 -168.09992345 -153.54207085\n",
      " -228.14241647 -180.07364416 -206.93548977 -273.59258333 -290.70805692]\n",
      "    [-142.01211892 -161.64767868 -177.15546764 -168.09992345 -153.54207085\n",
      " -228.14241647 -180.07364416 -206.93548977 -273.59258333 -290.70805692]\n",
      "    [-142.01211892 -161.64767868 -177.15546764 -168.09992345 -153.54207085\n",
      " -228.14241647 -180.07364416 -206.93548977 -273.59258333 -290.70805692]\n",
      "    [-142.01211892 -161.64767868 -177.15546764 -168.09992345 -153.54207085\n",
      " -228.14241647 -180.07364416 -206.93548977 -273.59258333 -290.70805692]\n",
      "Mean RMSE on test data kernel = \n",
      "    {'alpha': 0.001, 'kernel': RationalQuadratic(alpha=1, length_scale=10)}\n",
      "    -198.19094501735123\n",
      "    -198.19094501735123\n",
      "    -198.19094501735123\n",
      "    -198.19094501735123\n",
      "    -198.19094501735123\n",
      "    -198.19094501735123\n",
      "    -198.19094501735123\n",
      "    -198.19094501735123\n",
      "    -198.19094501735123\n",
      "    -198.19094501735123\n",
      "=================================================================\n",
      "R2 on train data kernel = \n",
      "    {'alpha': 0.001, 'kernel': RationalQuadratic(alpha=1, length_scale=10)}\n",
      "    [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "    [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "    [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "    [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "    [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "    [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "    [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "    [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "    [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "    [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "Mean R2 on training data kernel = \n",
      "    {'alpha': 0.001, 'kernel': RationalQuadratic(alpha=1, length_scale=10)}\n",
      "    0.9999999999136001\n",
      "    0.9999999999136001\n",
      "    0.9999999999136001\n",
      "    0.9999999999136001\n",
      "    0.9999999999136001\n",
      "    0.9999999999136001\n",
      "    0.9999999999136001\n",
      "    0.9999999999136001\n",
      "    0.9999999999136001\n",
      "    0.9999999999136001\n",
      "R2 on test data kernel = \n",
      "    {'alpha': 0.001, 'kernel': RationalQuadratic(alpha=1, length_scale=10)}\n",
      "    [-3.80953014 -4.52133493 -3.61538431 -3.66718436 -3.68559225 -5.692211\n",
      " -6.7866641  -6.13710489 -5.60073338 -9.0009391 ]\n",
      "    [-3.80953014 -4.52133493 -3.61538431 -3.66718436 -3.68559225 -5.692211\n",
      " -6.7866641  -6.13710489 -5.60073338 -9.0009391 ]\n",
      "    [-3.80953014 -4.52133493 -3.61538431 -3.66718436 -3.68559225 -5.692211\n",
      " -6.7866641  -6.13710489 -5.60073338 -9.0009391 ]\n",
      "    [-3.80953014 -4.52133493 -3.61538431 -3.66718436 -3.68559225 -5.692211\n",
      " -6.7866641  -6.13710489 -5.60073338 -9.0009391 ]\n",
      "    [-3.80953014 -4.52133493 -3.61538431 -3.66718436 -3.68559225 -5.692211\n",
      " -6.7866641  -6.13710489 -5.60073338 -9.0009391 ]\n",
      "    [-3.80953014 -4.52133493 -3.61538431 -3.66718436 -3.68559225 -5.692211\n",
      " -6.7866641  -6.13710489 -5.60073338 -9.0009391 ]\n",
      "    [-3.80953014 -4.52133493 -3.61538431 -3.66718436 -3.68559225 -5.692211\n",
      " -6.7866641  -6.13710489 -5.60073338 -9.0009391 ]\n",
      "    [-3.80953014 -4.52133493 -3.61538431 -3.66718436 -3.68559225 -5.692211\n",
      " -6.7866641  -6.13710489 -5.60073338 -9.0009391 ]\n",
      "    [-3.80953014 -4.52133493 -3.61538431 -3.66718436 -3.68559225 -5.692211\n",
      " -6.7866641  -6.13710489 -5.60073338 -9.0009391 ]\n",
      "    [-3.80953014 -4.52133493 -3.61538431 -3.66718436 -3.68559225 -5.692211\n",
      " -6.7866641  -6.13710489 -5.60073338 -9.0009391 ]\n",
      "Mean R2 on test data kernel = \n",
      "    {'alpha': 0.001, 'kernel': RationalQuadratic(alpha=1, length_scale=10)}\n",
      "    -5.251667846534912\n",
      "    -5.251667846534912\n",
      "    -5.251667846534912\n",
      "    -5.251667846534912\n",
      "    -5.251667846534912\n",
      "    -5.251667846534912\n",
      "    -5.251667846534912\n",
      "    -5.251667846534912\n",
      "    -5.251667846534912\n",
      "    -5.251667846534912\n",
      "=================================================================\n",
      "RMSE on train data kernel = \n",
      "    {'alpha': 0.01, 'kernel': Matern(length_scale=0.1, nu=1.5)}\n",
      "    [-8.88508501e-04 -8.88508503e-04 -8.88508477e-04 -8.87551426e-04\n",
      " -8.87544884e-04 -8.87614842e-04 -8.87614680e-04 -1.99899319e-05\n",
      " -8.87463774e-04 -8.87613352e-04]\n",
      "    [-8.88508501e-04 -8.88508503e-04 -8.88508477e-04 -8.87551426e-04\n",
      " -8.87544884e-04 -8.87614842e-04 -8.87614680e-04 -1.99899319e-05\n",
      " -8.87463774e-04 -8.87613352e-04]\n",
      "    [-8.88508501e-04 -8.88508503e-04 -8.88508477e-04 -8.87551426e-04\n",
      " -8.87544884e-04 -8.87614842e-04 -8.87614680e-04 -1.99899319e-05\n",
      " -8.87463774e-04 -8.87613352e-04]\n",
      "    [-8.88508501e-04 -8.88508503e-04 -8.88508477e-04 -8.87551426e-04\n",
      " -8.87544884e-04 -8.87614842e-04 -8.87614680e-04 -1.99899319e-05\n",
      " -8.87463774e-04 -8.87613352e-04]\n",
      "    [-8.88508501e-04 -8.88508503e-04 -8.88508477e-04 -8.87551426e-04\n",
      " -8.87544884e-04 -8.87614842e-04 -8.87614680e-04 -1.99899319e-05\n",
      " -8.87463774e-04 -8.87613352e-04]\n",
      "    [-8.88508501e-04 -8.88508503e-04 -8.88508477e-04 -8.87551426e-04\n",
      " -8.87544884e-04 -8.87614842e-04 -8.87614680e-04 -1.99899319e-05\n",
      " -8.87463774e-04 -8.87613352e-04]\n",
      "    [-8.88508501e-04 -8.88508503e-04 -8.88508477e-04 -8.87551426e-04\n",
      " -8.87544884e-04 -8.87614842e-04 -8.87614680e-04 -1.99899319e-05\n",
      " -8.87463774e-04 -8.87613352e-04]\n",
      "    [-8.88508501e-04 -8.88508503e-04 -8.88508477e-04 -8.87551426e-04\n",
      " -8.87544884e-04 -8.87614842e-04 -8.87614680e-04 -1.99899319e-05\n",
      " -8.87463774e-04 -8.87613352e-04]\n",
      "    [-8.88508501e-04 -8.88508503e-04 -8.88508477e-04 -8.87551426e-04\n",
      " -8.87544884e-04 -8.87614842e-04 -8.87614680e-04 -1.99899319e-05\n",
      " -8.87463774e-04 -8.87613352e-04]\n",
      "    [-8.88508501e-04 -8.88508503e-04 -8.88508477e-04 -8.87551426e-04\n",
      " -8.87544884e-04 -8.87614842e-04 -8.87614680e-04 -1.99899319e-05\n",
      " -8.87463774e-04 -8.87613352e-04]\n",
      "Mean RMSE on training data kernel = \n",
      "    {'alpha': 0.01, 'kernel': Matern(length_scale=0.1, nu=1.5)}\n",
      "    -0.0008010918371154313\n",
      "    -0.0008010918371154313\n",
      "    -0.0008010918371154313\n",
      "    -0.0008010918371154313\n",
      "    -0.0008010918371154313\n",
      "    -0.0008010918371154313\n",
      "    -0.0008010918371154313\n",
      "    -0.0008010918371154313\n",
      "    -0.0008010918371154313\n",
      "    -0.0008010918371154313\n",
      "RMSE on test data kernel = \n",
      "    {'alpha': 0.01, 'kernel': Matern(length_scale=0.1, nu=1.5)}\n",
      "    [-142.01211892 -161.64767868 -177.15546764 -168.09992345 -153.54207085\n",
      " -228.14241647 -180.07364416 -206.93548977 -273.59258333 -290.70805692]\n",
      "    [-142.01211892 -161.64767868 -177.15546764 -168.09992345 -153.54207085\n",
      " -228.14241647 -180.07364416 -206.93548977 -273.59258333 -290.70805692]\n",
      "    [-142.01211892 -161.64767868 -177.15546764 -168.09992345 -153.54207085\n",
      " -228.14241647 -180.07364416 -206.93548977 -273.59258333 -290.70805692]\n",
      "    [-142.01211892 -161.64767868 -177.15546764 -168.09992345 -153.54207085\n",
      " -228.14241647 -180.07364416 -206.93548977 -273.59258333 -290.70805692]\n",
      "    [-142.01211892 -161.64767868 -177.15546764 -168.09992345 -153.54207085\n",
      " -228.14241647 -180.07364416 -206.93548977 -273.59258333 -290.70805692]\n",
      "    [-142.01211892 -161.64767868 -177.15546764 -168.09992345 -153.54207085\n",
      " -228.14241647 -180.07364416 -206.93548977 -273.59258333 -290.70805692]\n",
      "    [-142.01211892 -161.64767868 -177.15546764 -168.09992345 -153.54207085\n",
      " -228.14241647 -180.07364416 -206.93548977 -273.59258333 -290.70805692]\n",
      "    [-142.01211892 -161.64767868 -177.15546764 -168.09992345 -153.54207085\n",
      " -228.14241647 -180.07364416 -206.93548977 -273.59258333 -290.70805692]\n",
      "    [-142.01211892 -161.64767868 -177.15546764 -168.09992345 -153.54207085\n",
      " -228.14241647 -180.07364416 -206.93548977 -273.59258333 -290.70805692]\n",
      "    [-142.01211892 -161.64767868 -177.15546764 -168.09992345 -153.54207085\n",
      " -228.14241647 -180.07364416 -206.93548977 -273.59258333 -290.70805692]\n",
      "Mean RMSE on test data kernel = \n",
      "    {'alpha': 0.01, 'kernel': Matern(length_scale=0.1, nu=1.5)}\n",
      "    -198.19094501735123\n",
      "    -198.19094501735123\n",
      "    -198.19094501735123\n",
      "    -198.19094501735123\n",
      "    -198.19094501735123\n",
      "    -198.19094501735123\n",
      "    -198.19094501735123\n",
      "    -198.19094501735123\n",
      "    -198.19094501735123\n",
      "    -198.19094501735123\n",
      "=================================================================\n",
      "R2 on train data kernel = \n",
      "    {'alpha': 0.01, 'kernel': Matern(length_scale=0.1, nu=1.5)}\n",
      "    [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "    [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "    [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "    [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "    [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "    [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "    [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "    [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "    [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "    [1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "Mean R2 on training data kernel = \n",
      "    {'alpha': 0.01, 'kernel': Matern(length_scale=0.1, nu=1.5)}\n",
      "    0.9999999999136001\n",
      "    0.9999999999136001\n",
      "    0.9999999999136001\n",
      "    0.9999999999136001\n",
      "    0.9999999999136001\n",
      "    0.9999999999136001\n",
      "    0.9999999999136001\n",
      "    0.9999999999136001\n",
      "    0.9999999999136001\n",
      "    0.9999999999136001\n",
      "R2 on test data kernel = \n",
      "    {'alpha': 0.01, 'kernel': Matern(length_scale=0.1, nu=1.5)}\n",
      "    [-3.80953014 -4.52133493 -3.61538431 -3.66718436 -3.68559225 -5.692211\n",
      " -6.7866641  -6.13710489 -5.60073338 -9.0009391 ]\n",
      "    [-3.80953014 -4.52133493 -3.61538431 -3.66718436 -3.68559225 -5.692211\n",
      " -6.7866641  -6.13710489 -5.60073338 -9.0009391 ]\n",
      "    [-3.80953014 -4.52133493 -3.61538431 -3.66718436 -3.68559225 -5.692211\n",
      " -6.7866641  -6.13710489 -5.60073338 -9.0009391 ]\n",
      "    [-3.80953014 -4.52133493 -3.61538431 -3.66718436 -3.68559225 -5.692211\n",
      " -6.7866641  -6.13710489 -5.60073338 -9.0009391 ]\n",
      "    [-3.80953014 -4.52133493 -3.61538431 -3.66718436 -3.68559225 -5.692211\n",
      " -6.7866641  -6.13710489 -5.60073338 -9.0009391 ]\n",
      "    [-3.80953014 -4.52133493 -3.61538431 -3.66718436 -3.68559225 -5.692211\n",
      " -6.7866641  -6.13710489 -5.60073338 -9.0009391 ]\n",
      "    [-3.80953014 -4.52133493 -3.61538431 -3.66718436 -3.68559225 -5.692211\n",
      " -6.7866641  -6.13710489 -5.60073338 -9.0009391 ]\n",
      "    [-3.80953014 -4.52133493 -3.61538431 -3.66718436 -3.68559225 -5.692211\n",
      " -6.7866641  -6.13710489 -5.60073338 -9.0009391 ]\n",
      "    [-3.80953014 -4.52133493 -3.61538431 -3.66718436 -3.68559225 -5.692211\n",
      " -6.7866641  -6.13710489 -5.60073338 -9.0009391 ]\n",
      "    [-3.80953014 -4.52133493 -3.61538431 -3.66718436 -3.68559225 -5.692211\n",
      " -6.7866641  -6.13710489 -5.60073338 -9.0009391 ]\n",
      "Mean R2 on test data kernel = \n",
      "    {'alpha': 0.01, 'kernel': Matern(length_scale=0.1, nu=1.5)}\n",
      "    -5.251667846534912\n",
      "    -5.251667846534912\n",
      "    -5.251667846534912\n",
      "    -5.251667846534912\n",
      "    -5.251667846534912\n",
      "    -5.251667846534912\n",
      "    -5.251667846534912\n",
      "    -5.251667846534912\n",
      "    -5.251667846534912\n",
      "    -5.251667846534912\n",
      "=================================================================\n"
     ]
    }
   ],
   "source": [
    "from sklearn.gaussian_process.kernels import RBF, RationalQuadratic as RQ\n",
    "from sklearn.gaussian_process.kernels import Matern as M, DotProduct as Dt\n",
    "\n",
    "\n",
    "r2_training_i_n = []\n",
    "r2_training_mean_i_n = []\n",
    "r2_test_i_n = []\n",
    "r2_test_mean_i_n = []\n",
    "\n",
    "rmse_training_i_n = []\n",
    "rmse_training_mean_i_n = []\n",
    "rmse_test_i_n = []\n",
    "rmse_test_mean_i_n = []\n",
    "\n",
    "for j in range(len(kernels)):\n",
    "    r2_training_i_n.append([])\n",
    "    r2_training_mean_i_n.append([])\n",
    "    r2_test_i_n.append([])\n",
    "    r2_test_mean_i_n.append([])\n",
    "\n",
    "    rmse_training_i_n.append([])\n",
    "    rmse_training_mean_i_n.append([])\n",
    "    rmse_test_i_n.append([])\n",
    "    rmse_test_mean_i_n.append([])\n",
    "    \n",
    "    for restarn_optimizer in n_restarts_optimizers:\n",
    "        model_k_n = GaussianProcessRegressor(kernel=kernels[j], n_restarts_optimizer = restarn_optimizer)\n",
    "\n",
    "        # scores = cross_validate(model_k_n, X, y, scoring=scoring, cv=10, return_train_score=True, return_estimator=True)\n",
    "    \n",
    "\n",
    "        # compute rmse on the training and test set predictions\n",
    "        rmse_training_i_n[j].append(scores['train_neg_root_mean_squared_error'])\n",
    "        rmse_training_mean_i_n[j].append(mean(scores['train_neg_root_mean_squared_error']))\n",
    "        rmse_test_i_n[j].append(scores['test_neg_root_mean_squared_error'])\n",
    "        rmse_test_mean_i_n[j].append(mean(scores['test_neg_root_mean_squared_error']))\n",
    "    \n",
    "        # compute r2 on the training and test set predictions\n",
    "        r2_training_i_n[j].append(scores['train_r2'])\n",
    "        r2_training_mean_i_n[j].append(mean(scores['train_r2']))\n",
    "        r2_test_i_n[j].append(scores['test_r2'])\n",
    "        r2_test_mean_i_n[j].append(mean(scores['test_r2']))\n",
    "\n",
    "        \n",
    "        \n",
    "    print (\"RMSE on train data kernel = \", kernels[j], *rmse_training_i_n[j], sep='\\n    ') \n",
    "    print (\"Mean RMSE on training data kernel = \", kernels[j], *rmse_training_mean_i_n[j], sep='\\n    ')\n",
    "    print (\"RMSE on test data kernel = \", kernels[j],  *rmse_test_i_n[j], sep='\\n    ') \n",
    "    print (\"Mean RMSE on test data kernel = \", kernels[j],  *rmse_test_mean_i_n[j], sep='\\n    ')\n",
    "\n",
    "    print('=================================================================')\n",
    "\n",
    "    print (\"R2 on train data kernel = \", kernels[j], *r2_training_i_n[j], sep='\\n    ') \n",
    "    print (\"Mean R2 on training data kernel = \", kernels[j],  *r2_training_mean_i_n[j], sep='\\n    ')\n",
    "    print (\"R2 on test data kernel = \", kernels[j],  *r2_test_i_n[j], sep='\\n    ') \n",
    "    print (\"Mean R2 on test data kernel = \", kernels[j],  *r2_test_mean_i_n[j], sep='\\n    ')\n",
    "    \n",
    "    print('=================================================================')\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7ac221e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'alpha': 0.01, 'kernel': RBF(length_scale=0.1)}, {'alpha': 0.01, 'kernel': DotProduct(sigma_0=10)}, {'alpha': 0.001, 'kernel': RationalQuadratic(alpha=1, length_scale=10)}, {'alpha': 0.01, 'kernel': Matern(length_scale=0.1, nu=1.5)}]\n"
     ]
    }
   ],
   "source": [
    "print(kernels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "108707f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAEVCAYAAADpbDJPAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/MnkTPAAAACXBIWXMAAAsTAAALEwEAmpwYAAAgJUlEQVR4nO3deZgdZZn38e8vHRIYlkQJGFYDCDiMhEZaFEYkEURUEBhFQHSI6BvCxTKivGxBJjMyI5syg/iyiLxRYQRZwr5jIkiA0IGQhUUUggRZAkIgrFnu+aOeTk5On9PdSfqcSvr5fa6rr66qU1X3Xafq1F311DlVigjMzCw//cpOwMzMyuECYGaWKRcAM7NMuQCYmWXKBcDMLFMuAGZmmXIBMDPLlAtAHZIWSZpW8XdSGr6bpFlp2FqSzk79Z69AjFNWYJoDJT0uaeLyTtvbuaTpvivp73ozl6r5t0r6YkX/lzvWxXLM4xZJg3s9uZJI2l/SdiswXbfvnaSNJV294tn1HkmjJJ1fY/gISbuu4DyHSfr6yme3fNt+2k88IWm6pAmryvYo/xCsNknzI2KdGsMvBP4QEZel/nnAByNiUW/F6Gaa24DTI+IPXYzTPyIWNiGXFuDPQFtEvLI80y5HjFFp/kc3Yv7LkUfLiqzjRpA0HrgpIjrtqFdk3a+q6q17SeOA+RFxzgrMcwRwfETs0wv5zaYH2376nOwB/C4iFko6EyAiTlzZHFZaRPivxh/FBlY97DvA34BngMuBG4BFwDTgIGAD4BrgofT3j2m6dYD/D8wApgNfAc6omPbyGrEOSePPBM5Mw04D5gNPAmdXjT8CuDfl9EegBTg75TEdOCKNtxFwT4o7E9itVi7AdcBUYBYwuvJ9AX4MPJryeT/lOTHFHJ/mOwM4rsZyDQN+l3K6G9g8DR8PXAi0p/z3AQYAfwHmVrzHo4DzK6a5AHgAeDq9B5cCjwPjK2LOBoYAY9J8pqV1ODG9vhdwP/AwcBWwTsV0Z6bhBwPHAo+l3K/oYtvZvSLOI8C6Ncb5XnqfZgLfrXhvHgd+nt73O4C1qqbblaXb4DRgK2AS8F/pvfs+sC/wYIp9F/ChNG31e3ceMDm9d1+tyGFmxfjXArcBTwFnVeTx7bSepqR8z6+xjDun9/WRFGfbHsz3W13NN+X3IvB8Wv7dqP+567QeKLaVeWnYcVXz7vTZqLd9UGwLS7b9Gss+m4ptp+q1A6jxmS9lP1d2AqvqH0t3iB1/B6Xh4zs+LKl/fkX3/wCfTt2bA4+n7jOB/6oY7wPV01bF3phix7cB0J9ih7l/em0SxVFH9TQjgLeALVL/aODU1D2QYuewBcUOYmwa3kLaOVXnQnFWA7BW+jCsn/oD+FrFeLOBIal7J+DOitcG18jzRuCw1H04cF3F+3obRbPk1sAcYE0qdlppvCX9aZorAAH7AW8A26d5TAVaq3NM/WtQFMt9KQrDPcDa6bUTgdMqpjuhYrq/AgPrLVvVMlYW//5Vr+9EseNYO70+C9iRYue2sCLv3wLfqDH/8Sy7DU4C/l/l9sXSs/vvAD+u895dld6r7YA/peHDWLYAPA0MSuviWWAziu1zNvDBiveyVgFYr2PZgT2Ba7qZ70Ys3e4HAPfVme84iqP47j53ndYDxefkpjrrrdNnowfbx5A681pm26mxfXRar2X89cfqeSciWpdzmj2B7SR19K8naZ00/OCOgRHxWjfz+QQwKSLmAki6HPgMxVF5V6ZExDOpey9guKSvpv5BFDvWh4BLJa1BsfOdVmdex0o6IHVvlqZ9laIwXlNnmqeBLSX9FLiZ4gi22i7AP6XuXwNnVbz224hYDDwl6Wngo3WXdKkbIyIkzQBeiogZAJJmUezMptWY5r8pTsdvlLQPxQ7wvrTeBlAc7XW4sqJ7OnC5pOvoel3cB/wkrbdrI2JO1eufBiZExFsp12spjmRvAJ6pWCdT0zL0RGWemwJXStooLc8ztSfhuvR+PybpQ3XGuTsi5qU8HwM+TLFT/H1E/C0NvwrYpsa0g4BfStqa4sBhjR7Mt3K7v7LOfKvV+9x1Wg8V49TS6bMhaXe63j66cmX1AEljKYr85T2cR0O5APSufsCnIuLdyoHdbHS96a3KsMAxEXF79UiSPgN8CRgv6ScR8auq10dQfKh2iYi3JU2iOFIDeDfqtIVHxGuSdgA+T9Hc8jWKo/yeqr4g1ZMLVO+l/4srujv6O23fqV35w0BHu7IozloOqTP/yvf0SxSFeF9grKTto0Z7e0ScIelm4IsUO47PR8QTPViWyuWBotiu1cPpKvP8KfCTiLghrctxPYhVbyOtzmd59hk/pGgeOUDSMIozld6Yb7Wanzug03roaiYRcU/1ZwN4ja63j65UrpOObW8fYI9IpwJl87eAetcdwDEdPZJaU+edwFEVwz+QOheko41qU4DdJQ1JF5AOAX6/nLncDhzZMX9J20haW9KHKY6Ufw5cAny8Ri6DgNfSzv+jwKe6iPMmxakykoYA/SLiGuDUinlXmszSs6FDKZoPOhwoqZ+krYAtKa51LJn/ypK0E3A8xen34jT4AeAfJX0kjbO2pE5HnZL6AZtFxESKZoBBFM0KteJsFREzIuJMiqPK6jOZe4H9Jf2dpLUp2oTvrZ5PF7p7TwZRtJEDHLYc8+2phyi2zw9I6k9xTau7PEb1YL4Ppvmun7bFA+uMV738NT93ddZD3feuzmejq+2jx9umpL2BE4AvR8TbPZmmGVwA6ltLy34N9IweTHMs0Ja+6vUYxVEwwOnAByTNlPQoMDINvxiYnk5Rl4iIF4CTKC6sPgpMjYjrlzP/SyguWD4saSZwEUvbQB+V9AjFRdX/rpHLbUB/SY9TXCB+oIs4FwO3qfha6ibAJEnTgMuAk2uMfwzwLUnTgW8C/1Lx2l8oit+twJh0RDeR4vR+mqSDlu8t6ORoinbriWl+l6TmhlHAb1JO91O76akFuCw1NT0CnBcRr9eJ8920rqcDC9LyLBERD1O0wU+h2OldEhGPLMdyXAH8X0mPpGJZbRxwlaSpQK9/Oysingf+kyL/+yjau+fVGPUs4EdpW+v2CD9t9+Mo1sF9FBfEa7kROCCtw92o/7mrtR6mA4skPSrpuKr5jqDqs9HN9lG57XfnfIpicWfK+8IeTNNw/hqorRLUxVcbbdUjaZ2ImJ/OACYAl0bEhLLzsuXjMwAzWxHj0pneTIqLzNeVmo2tEJ8BmK0gSd9i2SYsgPsi4qha45utalwAzMwyVerXQCVdSvG1qJcj4mPdjT9kyJAYNmxYw/MyM+tLpk6d+kpEbFA9vOzfAYynuDr+q27GA2DYsGG0t7cz5cQ7Adj5zM81LrMaHLfvx3Zcx+2LJD1ba3ipF4Ej4h6K+5qYmVmTlX4NIP1C8KaeNAH9/dBt4peH/YyNVfwo9a/ph3+NruYdRw2O2/ijptyW2XH7dtxVhaSpEdFWPXyV/xqopNGS2iW1v/5Ord+amJnZilitzgDa2trC1wD6ftwyYzuu4/ZFq+0ZgJmZNUapZwCSfkNx/40hwEvAv0bEL+qN33EGYGZmPVfvDKDUr4Gu4C1WzcysF7gJyMwsUy4AZmaZcgEwM8uUC4CZWaZcAMzMMuUCYGaWKRcAM7NMuQCYmWXKBcDMLFMuAGZmmXIBMDPLlAuAmVmmXADMzDLlAmBmlikXADOzTLkAmJllygXAzCxTLgBmZplyATAzy5QLgJlZplwAzMwy5QJgZpapUguApL0lPSnpT5JOKjMXM7PclFYAJLUAPwO+AGwHHCJpu7LyMTPLTZlnADsDf4qIpyPifeAKYL8S8zEzy0qZBWAT4LmK/jlp2DIkjZbULql97ty5TUvOzKyvW+UvAkfExRHRFhFtG2ywQdnpmJn1GWUWgOeBzSr6N03DzMysCcosAA8BW0vaQtIA4GDghhLzMTPLSv+yAkfEQklHA7cDLcClETGrrHzMzHJTWgEAiIhbgFvKzMHMLFer/EVgMzNrDBcAM7NMuQCYmWXKBcDMLFMuAGZmmXIBMDPLlAuAmVmmXADMzDLlAmBmlikXADOzTLkAmJllygXAzCxTLgBmZplyATAzy5QLgJlZplwAzMwy5QJgZpYpFwAzs0y5AJiZZcoFwMwsUy4AZmaZcgEwM8tUKQVA0oGSZklaLKmtjBzMzHJX1hnATOCfgHtKim9mlr3+ZQSNiMcBJJUR3szMWA2uAUgaLaldUvvcuXPLTsfMrM9o2BmApLuAoTVeGhsR1/d0PhFxMXAxQFtbW/RSemZm2WtYAYiIPRs1bzMzW3mrfBOQmZk1RllfAz1A0hxgF+BmSbeXkYeZWc7K+hbQBGBCGbHNzKzgJiAzs0y5AJiZZcoFwMwsUy4AZmaZcgEwM8uUC4CZWaZcAMzMMuUCYGaWKRcAM7NMuQCYmWXKBcDMLFMuAGZmmXIBMDPLlAuAmVmmXADMzDLlAmBmlikXADOzTLkAmJllygXAzCxTLgBmZplyATAzy1QpBUDS2ZKekDRd0gRJg8vIw8wsZ2WdAdwJfCwihgN/BE4uKQ8zs2yVUgAi4o6IWJh6HwA2LSMPM7OcrQrXAA4Hbq33oqTRktoltc+dO7eJaZmZ9W39GzVjSXcBQ2u8NDYirk/jjAUWApfXm09EXAxcDNDW1hYNSNXMLEsNKwARsWdXr0saBewD7BER3rGbmTVZwwpAVyTtDZwA7B4Rb5eRg5lZ7sq6BnA+sC5wp6Rpki4sKQ8zs2yVcgYQER8pI66ZmS21KnwLyMzMSuACYGaWKRcAM7NMuQCYmWXKBcDMLFPdFgBJ60naqsbw4Y1JyczMmqHLAiDpa8ATwDWSZkn6RMXL4xuZmJmZNVZ3ZwCnADtFRCvwLeDXkg5Ir6mRiZmZWWN190Owloh4ASAipkgaCdwkaTPA9+8xM1uNdXcG8GZl+38qBiOA/YB/aGBeZmbWYN2dARxJVZGIiDfTzdy+1rCszMys4bosABHxaJ2XFjUgFzMza6LuvgW0nqSTJZ0vaS8VjgGexmcAZmarte6agH4NvAbcD3yH4ltBAvaPiGmNTc3MzBqpuwKwZURsDyDpEuAFYPOIeLfhmZmZWUN19y2gBR0dEbEImOOdv5lZ39DdGcAOkt5I3QLWSv0CIiLWa2h2ZmbWMN19C6ilWYmYmVlz+W6gZmaZcgEwM8uUC4CZWaZcAMzMMlVKAZD0Q0nTJU2TdIekjcvIw8wsZ2WdAZwdEcPTcwZuAk4rKQ8zs2yVUgAi4o2K3rXxswXMzJquux+CNYyk/wD+GZgHjOxivNHAaIDNN9+8OcmZmWVAEY05+JZ0FzC0xktjI+L6ivFOBtaMiH/tbp5tbW3R3t7ei1mamfV9kqZGRFv18IadAUTEnj0c9XLgFqDbAmBmZr2nrG8BbV3Rux/wRBl5mJnlrKxrAGdI2hZYDDwLjCkpDzOzbJVSACLiK2XENTOzpfxLYDOzTLkAmJllygXAzCxTLgBmZplyATAzy5QLgJlZplwAzMwy5QJgZpYpFwAzs0y5AJiZZcoFwMwsUy4AZmaZcgEwM8uUC4CZWaZcAMzMMuUCYGaWKRcAM7NMuQCYmWXKBcDMLFMuAGZmmXIBMDPLVKkFQNL3JYWkIWXmYWaWo9IKgKTNgL2Av5SVg5lZzso8AzgXOAGIEnMwM8tWKQVA0n7A8xHxaBnxzcwM+jdqxpLuAobWeGkscApF809P5jMaGA2w+eab91p+Zma5U0RzW2AkbQ/cDbydBm0K/BXYOSJe7Gratra2aG9vb3CGZmZ9i6SpEdFWPbxhZwD1RMQMYMOOfkmzgbaIeKXZuZiZ5cy/AzAzy1TTzwCqRcSwsnMwM8uRzwDMzDLlAmBmlikXADOzTLkAmJllygXAzCxTLgBmZplyATAzy5QLgJlZplwAzMwy5QJgZpYpFwAzs0y5AJiZZcoFwMwsUy4AZmaZcgEwM8uUC4CZWaZcAMzMMuUCYGbWC1599VVaW1tpbW1l6NChbLLJJkv633///S6nbW9v59hjj21SpkspIpoedEW1tbVFe3t72WmYWR9x0EX3A3DlEbv06nzHjRvHOuusw/HHH79k2MKFC+nfv5yn8EqaGhFt1cN9BmBm1iCjRo1izJgxfPKTn+SEE05gypQp7LLLLuy4447suuuuPPnkkwBMmjSJffbZByiKx+GHH86IESPYcsstOe+88xqWX+kPhTcza7aOI/8Hn/nbMv29fSYAMGfOHCZPnkxLSwtvvPEG9957L/379+euu+7ilFNO4Zprruk0zRNPPMHEiRN588032XbbbTnyyCNZY401ej03FwAzswY68MADaWlpAWDevHkcdthhPPXUU0hiwYIFNaf50pe+xMCBAxk4cCAbbrghL730Eptuummv51ZKAZA0Dvg/wNw06JSIuKWMXMwsPx1H+o088u+w9tprL+n+wQ9+wMiRI5kwYQKzZ89mxIgRNacZOHDgku6WlhYWLlzYkNzKPAM4NyLOKTG+mVlTzZs3j0022QSA8ePHl5sMvghsZhm78ohdGnr0X+2EE07g5JNPZscdd2zYUf3yKOVroKkJaBTwBtAOfD8iXqsz7mhgNMDmm2++07PPPtukLM3M+oZ6XwNtWAGQdBcwtMZLY4EHgFeAAH4IbBQRh3c3T/8OwMxs+dUrAA27BhARe/ZkPEk/B25qVB5mZlZbKdcAJG1U0XsAMLOMPMzMclbWReCzJM2QNB0YCRzX0wkXVV04qe5vFMdt3gWr3JbZcft23FVZKQUgIr4ZEdtHxPCI+HJEvNCT6V557lkuOv7oJStu0cKFXHT80fzie2Mamu8vvjfGcZsQt8zYjuu4OVqtvgYawMuDhy5ZkRcdfzQvDx7Ke4sbV80XLVzIe4sdt9Fxy4ztuI6bq9XrbqA77RSH7/YJXh689MtFG77+Ikeccz4tDbzLXuUG47iN/e1gbsvsuGXGfYEjzvnZ0rgRIK1wjFdffZU99tgDgBdffJGWlhY22GADAKZMmcKAAQO6nH7SpEkMGDCAXXfddYVzqKdv3A1U4ohzzl9mUDN2Si39+ztuE+KWGdtx84o7gvsZs9egJffoIQJuOxkm/miFY6y//vpMmzaNadOmMWbMGI477rgl/d3t/KEoAJMnT17h+Cti9SoAEVx0/NHLDKps12uUjqMHx238qXJuy+y4ZcQN1uQ9+k25iMW3nrh05//gBfDuvKK/l0ydOpXdd9+dnXbaic9//vO88EJxufO8885ju+22Y/jw4Rx88MHMnj2bCy+8kHPPPZfW1lbuvffeXsuhK6tVAZg75y+8PHgoG77+Ij849VQ2fP3FZdr1GqHy1NFxG/tBzW2ZHbesuD/g4de35QF2pN+Ui+DfBhc7/08eCXv/aKWagSpFBMcccwxXX301U6dO5fDDD2fs2LEAnHHGGTzyyCNMnz6dCy+8kGHDhi1z1rDbbrv1Sg7dWa0KgFi2vfCIc85nw9dfZGA/GnYK2dK/PwP7OW6j45YZ23FzjPszHn5922VH7MWdP8B7773HzJkz+dznPkdrayunn346c+bMAWD48OEceuihXHbZZaU9JQxWt4vAbW3x4AMPLLOhLFq4sClt09VxHLfvxXbcjOJGsPjWE4szgA69eAYwbtw4WlpauOWWW7j//vs757JoEffccw833ngjt956KzNmzOD000/v9BjJ3tI3LgLT+SihWTslx23eUUpuy+y4TY6b2vz7Tbmo2On/6+vF/wcvKK4F9NJB8cCBA5k7d+6SArBgwQJmzZrF4sWLee655xg5ciRnnnkm8+bNY/78+ay77rq8+eabvRK7p1a7AmBmtlIkWHPQskf8e/+o6F9zUK81A/Xr14+rr76aE088kR122IHW1lYmT57MokWL+MY3vsH222/PjjvuyLHHHsvgwYPZd999mTBhQlMvAq92TUC+G6iZ9Yrq7/2v5O8AVmV9pgnIzKxXVO/s++jOvysuAGZmmXIBMDPLlAuAmVmmXADMzDLlAmBmlikXADOzTLkAmJllygXAzCxTLgBmZplyATAzy5QLgJlZpkorAJKOkfSEpFmSziorDzOzXJXyKBpJI4H9gB0i4j1JG5aRh5lZzso6AzgSOCMi3gOIiJdLysPMLFtlPYxyG2A3Sf8BvAscHxEP1RpR0mhgdOqdL+nJ1D0EeKXhmXbmuH0/tuM6bl/z4VoDG1YAJN0FDK3x0tgU94PAp4BPAL+VtGXUeDpNRFwMXFxj/u21HnDQaI7b92M7ruPmomEFICL2rPeapCOBa9MOf4qkxRRVeW6j8jEzs2WVdQ3gOmAkgKRtgAHkd0pmZlaqsq4BXApcKmkm8D5wWK3mn250ahZqEsft+7Ed13GzsFo9FN7MzHqPfwlsZpYpFwAzs0ytdgVA0qWSXk7XD5oZd01JUyQ9mm5f8W9NjD1b0gxJ0yS1Nynmtilex98bkr7boFid1qmkD0q6U9JT6f8Hmhh7nKTnK5b9i70cczNJEyU9lralf0nDG77M9bZjSVtIelDSnyRdKWlAA2J32o4bsczLsz2pcF5a7umSPr6y8Vcnq10BAMYDe5cQ9z3gsxGxA9AK7C3pU02MPzIiWpv1/eWIeDLFawV2At4GJjQo3Hg6r9OTgLsjYmvg7tTfrNgA53Ysf0Tc0ssxFwLfj4jtKH4Lc5Sk7WjOMtfbjs+kWOaPAK8B325AbOi8HTdimcfT8+3pC8DW6W80cEEvxF9trHYFICLuAf5WQtyIiPmpd430l8sV9D2AP0fEs42YeZ11uh/wy9T9S2D/JsZuqIh4ISIeTt1vAo8Dm9CEZe5iO/4scHUjY9fR68u8nNvTfsCv0vvyADBY0kYrm8PqYrUrAGWS1CJpGvAycGdEPNik0AHcIWlqujVGsx0M/KbJMT8UES+k7heBDzU5/tGpSeDSRjU/AUgaBuwIPEiTlrl6Owb+DLweEQvTKHMoClJvq7UdN2s914uzCfBcxXiNWvZVkgvAcoiIRalJZFNgZ0kfa1LoT0fExylOV4+S9JkmxSW1BX8ZuKpZMaul34g082zrAmAriiaSF4AfNyKIpHWAa4DvRsQbla81cpmrt2Pgo42IU0OX23Gz1nMJ29MqywVgBUTE68BEmnQtIiKeT/9fpmiH37kZcZMvAA9HxEtNjAnwUsepePrftDvGRsRLaSe5GPg5DXi/Ja1BsfO/PCKuTYObuswV2/EuFE0fHT8M3RR4vgHxam3HzVrmenGeBzarGK8hy76qcgHoIUkbSBqcutcCPgc80YS4a0tat6Mb2Ato5jegDqH5zT8ANwCHpe7DgOubFbiqDfgAevn9liTgF8DjEfGTipcavsx1tuPHKQrBVxsVu4vtuFnruV6cG4B/Tt8G+hQwr6KpqO+LiNXqj2Jn9AKwgKK97ttNijsceASYTrHhntakuFsCj6a/WcDYJr7XawOvAoOavU6B9Sm+rfEUcBfwwSbG/jUwI63rG4CNejnmpymaIKYD09LfF5uxzPW247SdTQH+RNHcN7CX49bcjhuxzMuzPQECfkZxHWQG0NbIbX1V+/OtIMzMMuUmIDOzTLkAmJllygXAzCxTLgBmZplyATAzy5QLgJlZplwArBSSFqXbAs+UdGPHj5OWcx6tK3KrZknDJH19eadbzhijJG1c0X9JuuNnT6dvk3ReY7IzK7gAWFneieK2wB+juHPjUSswj1aKH1D1WLrdwTCgoQUAGAUsKQAR8Z2IeKynE0dEe0QcuzIJVNzawawmFwBbFdxPugOjpK0k3ZbuGHmvpI+m4Qems4VHJd2TblL378BB6UziIEk7S7pf0iOSJkvaNk07StINkn5H8WvQM4Dd0nTHSfoHFQ9JmZbuALp1dYKSDkkPM5kp6cyK4fMlnavi4Sp3p1stfBVoAy5P81xL0iRJbRXTnJ2muSvlPUnS05K+nMYZIemm1H2Llj6cZp6kw9IdPc+W9FDK+YiK6e6VdAPwWLoFw83pfZsp6aB6K0HSGSoeUjNd0jkrvVZt1Vf2T5H9l+cfMD/9b6G49cDeqf9uYOvU/Ungd6l7BrBJ6h6c/o8Czq+Y53pA/9S9J3BNxXhzWPrz/xHATRXT/RQ4NHUPANaqynVj4C/ABkB/4HfA/um1qJj2tI58gElU3Fagsj9N84XUPQG4g+K+/DsA02rlmIbtRHELh0EUDy85NQ0fCLQDW6Tp3gK2SK99Bfh5xTwG1Vkf6wNPwpK7AwwuexvxX+P/fIpoZVlLxT3pN6G4Gdmd6fbIuwJXFfdLA4qdG8B9wHhJvwWupbZBwC/TEXxQ7FQ73BkR9R78cj8wVtKmwLUR8VTV658AJkXEXABJlwOfAa4DFgNXpvEu6yK3Su8Dt6XuGcB7EbFA0gyK5qlOJA2huEfR1yJinqS9gOHpbAOKZd86zXtKRDxTMf8fp7OWmyLi3jo5zQPeBX6Rzjxu6sFy2GrOTUBWlneiuCf9hyluyHUUxfb4eix9FGNrRPw9QESMAU6luHXvVEnr15jnD4GJUVxX2BdYs+K1t+olEhH/Q/HMg3eAWyR9diWWqyc311oQER3jLaZ4TCNR3H6600GZpBbgCuDfI6LjzqQCjql4n7aIiDvSa0uWNSL+CHycohCcLum0mkkXD4PZmeKpYPuwtEBZH+YCYKWKiLeBY4HvUzx3+BlJB8KSB3bvkLq3iogHI+I0YC5FIXgTWLdidoNYei/3UV2EXWY6SVsCT0fEeRS3CR5eNf4UYHdJQ9LO+BDg9+m1fiy9jfLXgT/UirGSzgCmR8QVFcNuB45U8VwBJG2j4jbLy0jfRHo7Ii4DzqYoBp2ks69BUTz/+DiK5ijr49wEZKWLiEckTafYsR4KXCDpVIomnCsobiF8dmraEcV1gkcp2uVPSk1JPwLOomgCOhW4uYuQ04FFkh6leID4QOCbkhZQPC7wP6vye0HSSRT3zBdwc0R03E/+LYqnw51K8ZCRjous44ELJb1D8cCVlXE8MCstJxTXGi6haC56WEV72VxqP093e4r3bjHF7ZGPrBNjXeB6SWtSLOP3VjJnWw34dtBmK0HS/IhYp+w8zFaEm4DMzDLlMwCzzEiaQPGV0UonRsTtZeRj5XEBMDPLlJuAzMwy5QJgZpYpFwAzs0y5AJiZZep/AcQLRXdewM6EAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(n_restarts_optimizers_s, r2_training_mean_i_n[0],marker=\"+\")\n",
    "plt.scatter(n_restarts_optimizers_s, r2_test_mean_i_n[0],marker=\"x\")\n",
    "plt.scatter(n_restarts_optimizers_s, r2_training_mean_i_n[1],marker=\"+\")\n",
    "plt.scatter(n_restarts_optimizers_s, r2_test_mean_i_n[1],marker=\"x\")\n",
    "plt.scatter(n_restarts_optimizers_s, r2_training_mean_i_n[2],marker=\"+\")\n",
    "plt.scatter(n_restarts_optimizers_s, r2_test_mean_i_n[2],marker=\"x\")\n",
    "plt.scatter(n_restarts_optimizers_s, r2_training_mean_i_n[3],marker=\"+\")\n",
    "plt.scatter(n_restarts_optimizers_s, r2_test_mean_i_n[3],marker=\"x\")\n",
    "\n",
    "\n",
    "plt.xlim([-0.1, 11])\n",
    "plt.ylim([-6, 1.1])\n",
    "plt.xlabel(\"Restarts optimizers_s\")\n",
    "plt.ylabel(\"R2\")\n",
    "legend_labels = [\"Train\", \"Test\"]\n",
    "plt.legend(frameon=False, loc=4,labels=legend_labels,  borderpad=1)\n",
    "plt.title(\"Effect of restarts optimizers_s on training and test set r2\", fontsize=10)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "632af794",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
